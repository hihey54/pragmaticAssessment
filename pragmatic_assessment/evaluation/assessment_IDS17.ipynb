{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from supportFunctions import *\n",
    "\n",
    "root_folder = \"..\\\\data\\\\IDS17\\\\flows\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PARAMETERS #####\n",
    "\n",
    "## Generic parameters\n",
    "temporal = True # used to determine if this evaluation assumes a \"temporal\" dependency among its samples\n",
    "base_clf = 'dt' # name of the classifier used for this \"run\". Available names: ['dt', 'rf', 'hgb', 'lr']. You can add more by editing the supportFunctions file\n",
    "test_size = 0.2 # proportion of the dataset used for testing. We always kept it fixed to 0.2 for our paper\n",
    "train_size = 100 # proportion of the REMAINING data that are used for training (if >1, then it will take that exact amount). To reproduce the results of the paper, use: 100 (for \"limited\" training data) or 0.2 or 0.5 or 0.99 (for scarce, moderate, abundant training data, respectively) \n",
    "agreement = 0.5 # from 0 to 1. Proportion of classifiers that must agree on an attack (for the ensemble). This is fixed in our paper.\n",
    "max_size = 500000 ## maximum amount of samples to include when creating the initial dataframes. This is fixed in our paper\n",
    "max_size_atk = int(max_size / 3) # maximum amount of malicious samples per class. This is fixed in our paper\n",
    "\n",
    "## Adversarial Attacks parameters\n",
    "# This attack involves TCP because no malicious UDP flows exist\n",
    "atk_intensity = 1 # send 100 packets of 10 bytes over 100 seconds\n",
    "pkt_intensity = atk_intensity * 10 # \n",
    "byt_intensity = pkt_intensity * 100 # \n",
    "dur_intensity = atk_intensity * 100 # consider seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading input data\n",
    "\n",
    "malicious_folder = root_folder + \"malicious/\"\n",
    "\n",
    "benign_file = root_folder + \"benign.csv\"\n",
    "benign_df = pd.read_csv(benign_file, header='infer', index_col=0)\n",
    "benign_df = benign_df.sample(min(max_size, len(benign_df)))\n",
    "#sort by timestamp\n",
    "if temporal == True:\n",
    "    benign_df = benign_df.sort_values(by=['Timestamp'])\n",
    "benign_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "attack_names = [\"ddos\", \"geye\", \"hulk\", \"http\", \"loris\", \"ftp\", \"pscan\", \"ssh\", \"other\"]\n",
    "\n",
    "ddos_file = malicious_folder + \"dos-ddos.csv\"\n",
    "geye_file = malicious_folder + \"dos-goldeneye.csv\"\n",
    "hulk_file = malicious_folder + \"dos-hulk.csv\"\n",
    "http_file = malicious_folder + \"dos-slowhttp.csv\"\n",
    "loris_file = malicious_folder + \"dos-slowloris.csv\"\n",
    "ftp_file = malicious_folder + \"ftp-patator.csv\"\n",
    "pscan_file = malicious_folder + \"portscan.csv\"\n",
    "ssh_file = malicious_folder + \"ssh-patator.csv\"\n",
    "other_file = malicious_folder + \"other.csv\"\n",
    "\n",
    "\n",
    "\n",
    "for a in attack_names:\n",
    "    exec(f\"{a}_df = pd.read_csv({a}_file, header='infer', index_col=0)\")\n",
    "    exec(f\"{a}_df = {a}_df.sample(min(max_size_atk, len({a}_df)))\")\n",
    "    # sort by timestamp\n",
    "    if temporal == True:\n",
    "        exec(f\"{a}_df = {a}_df.sort_values(by=['Timestamp'])\")\n",
    "    exec(f\"{a}_df.reset_index(inplace=True, drop=True)\")\n",
    "    exec(f\"{a}_df['Label'] = a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining Train and Test sets for each class\n",
    "\n",
    "df_list = [benign_df]\n",
    "for a in attack_names:\n",
    "    exec(f\"df_list.append({a}_df)\")\n",
    "\n",
    "if temporal == True:\n",
    "    for dummy_df in df_list:\n",
    "        if train_size <=1:\n",
    "            train_threshold = int(((1-test_size) * train_size) * len(dummy_df))\n",
    "        else:\n",
    "            train_threshold = int(100)\n",
    "        test_threshold = len(dummy_df) - int(test_size * len(dummy_df))\n",
    "        dummy_df['index'] = dummy_df.index\n",
    "        dummy_df['is_test'] = np.where(dummy_df['index'] >= test_threshold , True, False)\n",
    "        dummy_df['is_train'] = np.where(dummy_df['index'] <= train_threshold , True, False)\n",
    "else:\n",
    "    for dummy_df in df_list:\n",
    "        if train_size <= 1:\n",
    "            train_threshold = test_size + (1-test_size)*train_size\n",
    "        else:\n",
    "            train_threshold = test_size + ((train_size * 100) / (len(dummy_df)) / 100)       \n",
    "        dummy_df['seed'] = (np.random.uniform(0,1,len(dummy_df)))\n",
    "        dummy_df['is_test'] = np.where(dummy_df['seed'] <= test_size, True, False)\n",
    "        dummy_df['is_train'] = np.where((dummy_df['seed'] <= train_threshold) & (dummy_df['is_test']==False), True, False)\n",
    "\n",
    "# get all together\n",
    "all_df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "& 0 & \\textit{Benign} & 497220 & \\\\ \\cline{2-4}\n",
      "& 1 & \\textit{ddos} & 95123 \\\\ \\cline{2-4}\n",
      "& 2 & \\textit{geye} & 7567 \\\\ \\cline{2-4}\n",
      "& 3 & \\textit{hulk} & 158469 \\\\ \\cline{2-4}\n",
      "& 4 & \\textit{http} & 1742 \\\\ \\cline{2-4}\n",
      "& 5 & \\textit{loris} & 4001 \\\\ \\cline{2-4}\n",
      "& 6 & \\textit{ftp} & 3973 \\\\ \\cline{2-4}\n",
      "& 7 & \\textit{pscan} & 159151 \\\\ \\cline{2-4}\n",
      "& 8 & \\textit{ssh} & 2980 \\\\ \\cline{2-4}\n",
      "& 9 & \\textit{other} & 971 \\\\ \\cline{2-4}\n"
     ]
    }
   ],
   "source": [
    "def handle_categorical(df):\n",
    "    ## Handling categorical data\n",
    "    df_dummy = df.copy(deep=True)\n",
    "    df_dummy['Nature'] = np.where(df_dummy['Label'].str.contains('BENIGN'),0,1)\n",
    "    \n",
    "    for column_name in df_dummy.columns:\n",
    "        if column_name == ('SrcPort_type'):\n",
    "            df_dummy[column_name] = pd.factorize(df_dummy[column_name])[0]\n",
    "        elif column_name == ('DstPort_type'):\n",
    "            df_dummy[column_name] = pd.factorize(df_dummy[column_name])[0]\n",
    "        elif column_name == ('Protocol'):\n",
    "            df_dummy[column_name+\"-f\"] = pd.factorize(df_dummy[column_name])[0]\n",
    "        else:\n",
    "            pass\n",
    "    return df_dummy\n",
    "\n",
    "all_df = handle_categorical(all_df)\n",
    "all_df['Label_cat'] = pd.factorize(all_df['Label'])[0]\n",
    "\n",
    "all_df['int2int'] = np.where( ((all_df['SrcIP_internal']==True) & (all_df['DstIP_internal']==True)), True, False)\n",
    "\n",
    "all_df = all_df[~all_df['Label_original'].str.contains(\"Attempted\")] # removing \"attempted\"\n",
    "\n",
    "all_df['Duration(s)'] = all_df['FlowDuration'] / 1000000\n",
    "# all_df['totPkt'] = all_df['FlowPackets/s'] * all_df['Duration(s)']\n",
    "# all_df['totByt'] = all_df['FlowBytes/s'] * all_df['Duration(s)']\n",
    "\n",
    "all_df['DstPkt'] = all_df['BwdPackets/s'] * all_df['Duration(s)']\n",
    "all_df['SrcPkt'] = all_df['FwdPackets/s'] * all_df['Duration(s)']\n",
    "\n",
    "all_df['DstByt'] = all_df['DstPkt'] * all_df['BwdSegmentSizeAvg']\n",
    "all_df['SrcByt'] = all_df['SrcPkt'] * all_df['FwdSegmentSizeAvg']\n",
    "\n",
    "all_df['totPkt'] = all_df['SrcPkt'] + all_df['DstPkt']\n",
    "all_df['totByt'] = all_df['SrcByt'] + all_df['DstByt']\n",
    "\n",
    "\n",
    "\n",
    "all_train, all_test = all_df[all_df['is_train']==True], all_df[all_df['is_test']==True]\n",
    "\n",
    "### SPLITTING ALL BACK ####\n",
    "benign_df = all_df[all_df['Label']=='BENIGN']\n",
    "benign_train = benign_df[benign_df['is_train']==True]\n",
    "benign_test = benign_df[benign_df['is_test']==True]\n",
    "for a in attack_names:\n",
    "    exec(f\"{a}_df = all_df[all_df['Label']=='{a}']\")\n",
    "    \n",
    "malicious_df = all_df[all_df['Label']!='BENIGN']\n",
    "malicious_train, malicious_test = malicious_df[malicious_df['is_train']==True], malicious_df[malicious_df['is_test']==True]\n",
    "\n",
    "\n",
    "print(\"& 0 & \\\\textit{{Benign}} & {} & \\\\\\\\ \\\\cline{{2-4}}\".format(len(benign_df)))\n",
    "\n",
    "\n",
    "for i,a in enumerate(attack_names):\n",
    "    exec(f\"print('& {i+1} & \\\\\\\\textit{{{{{a}}}}} & {{}} \\\\\\\\\\\\\\\\ \\\\\\\\cline{{{{2-4}}}}'.format(len({a}_df)))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature sets\n",
    "\n",
    "# the following is the \"complete\" feature set\n",
    "\n",
    "features = ['Protocol-f',\n",
    "       'FlowDuration', \n",
    "       'FwdPacketLengthMax', 'FwdPacketLengthMin', 'FwdPacketLengthMean',\n",
    "       'FwdPacketLengthStd', 'BwdPacketLengthMax', 'BwdPacketLengthMin',\n",
    "       'BwdPacketLengthMean', 'BwdPacketLengthStd', 'FlowBytes/s',\n",
    "       'FlowPackets/s', 'FlowIATMean', 'FlowIATStd', 'FlowIATMax',\n",
    "       'FlowIATMin', 'FwdIATTotal', 'FwdIATMean', 'FwdIATStd', 'FwdIATMax',\n",
    "       'FwdIATMin', 'BwdIATTotal', 'BwdIATMean', 'BwdIATStd', 'BwdIATMax',\n",
    "       'BwdIATMin', 'FwdPSHFlags', 'BwdPSHFlags', 'FwdURGFlags', 'BwdURGFlags',\n",
    "       'FwdHeaderLength', 'BwdHeaderLength', 'FwdPackets/s', 'BwdPackets/s',\n",
    "       'PacketLengthMin', 'PacketLengthMax', 'PacketLengthMean',\n",
    "       'PacketLengthStd', 'PacketLengthVariance', 'FINFlagCount',\n",
    "       'SYNFlagCount', 'RSTFlagCount', 'PSHFlagCount', 'ACKFlagCount',\n",
    "       'URGFlagCount', 'CWRFlagCount', 'ECEFlagCount', 'Down/UpRatio',\n",
    "       'AveragePacketSize', 'FwdSegmentSizeAvg', 'BwdSegmentSizeAvg',\n",
    "       'FwdBytes/BulkAvg', 'FwdPacket/BulkAvg', 'FwdBulkRateAvg',\n",
    "       'BwdBytes/BulkAvg', 'BwdPacket/BulkAvg', 'BwdBulkRateAvg',\n",
    "       'SubflowFwdPackets', 'SubflowFwdBytes', 'SubflowBwdPackets',\n",
    "       'SubflowBwdBytes', 'FWDInitWinBytes', 'BwdInitWinBytes',\n",
    "       'FwdActDataPkts', 'FwdSegSizeMin', 'ActiveMean', 'ActiveStd',\n",
    "       'ActiveMax', 'ActiveMin', 'IdleMean', 'IdleStd', 'IdleMax', 'IdleMin',\n",
    "       'SrcPort_type', 'DstPort_type',\n",
    "       'int2int'\n",
    "       \n",
    "       ]\n",
    "\n",
    "# this is for the \"essential\" feature set\n",
    "small_features = ['Protocol-f', 'Duration(s)', 'totPkt', 'totByt',\n",
    "                'DstPkt', 'SrcPkt', 'DstByt', 'SrcByt', 'SrcPort_type', \n",
    "                  'DstPort_type', 'FwdPSHFlags', 'BwdPSHFlags', 'FwdURGFlags', 'BwdURGFlags',\n",
    "                  'FINFlagCount',\n",
    "       'SYNFlagCount', 'RSTFlagCount', 'PSHFlagCount', 'ACKFlagCount',\n",
    "       'URGFlagCount', 'CWRFlagCount', 'ECEFlagCount',\n",
    "                  'int2int'\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86789\n"
     ]
    }
   ],
   "source": [
    "# creating adversarial dataset\n",
    "mal_base = malicious_df[((malicious_df['Protocol']==6)) & (malicious_df['is_test']==True)]\n",
    "mal_adv = mal_base.copy(deep=True)\n",
    "print(len(mal_base))\n",
    "\n",
    "\n",
    "\n",
    "# attacking\n",
    "max_dur = mal_adv['Duration(s)'].max()\n",
    "min_dur = mal_adv['Duration(s)'].min()\n",
    "mal_adv['Duration(s)'] = mal_adv['Duration(s)'] + dur_intensity # we increase the duration in seconds\n",
    "mal_adv['Duration(s)'] = np.where(mal_adv['Duration(s)'] > max_dur, max_dur, mal_adv['Duration(s)'])\n",
    "mal_adv['Duration(s)'] = np.where(mal_adv['Duration(s)'] < min_dur, min_dur, mal_adv['Duration(s)'])\n",
    "\n",
    "mal_adv['DstPkt'] = mal_adv['DstPkt'] + pkt_intensity\n",
    "mal_adv['SrcPkt'] = mal_adv['SrcPkt'] + (pkt_intensity * 2)\n",
    "mal_adv['DstByt'] = mal_adv['DstByt'] + (pkt_intensity)\n",
    "mal_adv['SrcByt'] = mal_adv['SrcByt'] + byt_intensity \n",
    "\n",
    "mal_adv['SYNFlagCount'] = mal_adv['SYNFlagCount'] + pkt_intensity\n",
    "mal_adv['ACKFlagCount'] = mal_adv['SYNFlagCount'] + pkt_intensity\n",
    "mal_adv['totPkt'] = mal_adv['SrcPkt'] + mal_adv['DstPkt']\n",
    "mal_adv['totByt'] = mal_adv['SrcByt'] + mal_adv['DstByt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FROM NOW ON, THE CODE IS ALWAYS THE SAME FOR EVERY DATASET!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Assessment on \"Complete\" feature set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## BINARY CLASSIFIER (Complete features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing bin......done! Training time: 0.014950s\tInference time: 0.090706s\n",
      "Total Misclassifications: 29505 out of 186349 (Recall: 0.999965\tFPR: 0.296333)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70055</td>\n",
       "      <td>29502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>86789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred      0      1\n",
       "True              \n",
       "0     70055  29502\n",
       "1         3  86789"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bClf, bPred, bResult = develop_clf(all_train, all_test, features, clf_name='bin', label='Nature', clf_type=base_clf, verbose=1)\n",
    "\n",
    "if (bResult.acc == 0):\n",
    "    bErr = int(len(all_test) * (1-bResult.acc_multi))\n",
    "else:\n",
    "    bErr = int(len(all_test) * (1-bResult.acc))\n",
    "\n",
    "print(\"Total Misclassifications: {} out of {} (Recall: {:5f}\\tFPR: {:5f})\".format(bErr, len(all_test), bResult.rec, bResult.fpr))\n",
    "pd.crosstab(all_test['Nature'], bPred, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MULTI-CLASS CLASSIFIER - cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing mc......done! Training time: 0.015484s\tInference time: 0.048845s\n",
      "Total Misclassifications: 1884 out of 86792\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1512</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>531</td>\n",
       "      <td>31137</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>203</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>591</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>794</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>59</td>\n",
       "      <td>31680</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>577</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred      1     2      3    4    5    6      7    8   9\n",
       "True                                                   \n",
       "1     19003     0      0    0    0   21      0    0   0\n",
       "2         0  1512      0    0    0    0      0    0   1\n",
       "3         0   531  31137    0    7    0      4    0  14\n",
       "4         0   127      1  203   16    0      0    0   1\n",
       "5         0    59      0  591    1   41     92    0  16\n",
       "6         0     0      0    0    0  794      0    0   0\n",
       "7        36    19     18    0   18   59  31680    0   0\n",
       "8         0     2      0    0    0   17      0  577   0\n",
       "9         0     1      0    0  178    0      0   15   0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the classifier that analyzes ONLY the malicious samples that \"receives\" from the initial binary classifier\n",
    "# It is trained on the same training set---but without using the benign samples\n",
    "# It is tested on the malicious samples in the test set that are flagged as malicious by the binary classifier\n",
    "\n",
    "\n",
    "mcClf, mcPred, mcResult = develop_clf(malicious_train, malicious_test, features, clf_name='mc', label='Label_cat', clf_type=base_clf, verbose=1)\n",
    "mcErr = int(len(malicious_test) * (1-mcResult.acc_multi))\n",
    "print(\"Total Misclassifications: {} out of {}\".format(mcErr, len(malicious_test)))\n",
    "pd.crosstab(malicious_test['Label_cat'], mcPred, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Misclassifications (among the malicious samples): 1884 out of 86789\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1512</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>531</td>\n",
       "      <td>31137</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>203</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>591</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>794</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>59</td>\n",
       "      <td>31677</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>577</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred      1     2      3    4    5    6      7    8   9\n",
       "True                                                   \n",
       "1     19003     0      0    0    0   21      0    0   0\n",
       "2         0  1512      0    0    0    0      0    0   1\n",
       "3         0   531  31137    0    7    0      4    0  14\n",
       "4         0   127      1  203   16    0      0    0   1\n",
       "5         0    59      0  591    1   41     92    0  16\n",
       "6         0     0      0    0    0  794      0    0   0\n",
       "7        36    19     18    0   18   59  31677    0   0\n",
       "8         0     2      0    0    0   17      0  577   0\n",
       "9         0     1      0    0  178    0      0   15   0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We select the samples flagged as malicious by the initial classifier.\n",
    "# Of course, samples flagged as malicious that are NOT actually malicious will always be misclassified\n",
    "\n",
    "all_test['bPred'] = bPred\n",
    "mc_test = all_test[(all_test['bPred']==1) & (all_test['Nature']==1)]\n",
    "if (len(mc_test)==0):\n",
    "    # in this case, this classifier receives nothing\n",
    "    print(\"There is no malicious sample flagged as malicious to analyze!\")\n",
    "\n",
    "mcPred_m = mcClf.predict(mc_test[features])\n",
    "mcResult.acc_multic = accuracy_score(mc_test['Label_cat'], mcPred_m, normalize=True, sample_weight=None)\n",
    "mcErr_m = int((1-mcResult.acc_multic) * len(mc_test))\n",
    "print(\"Total Misclassifications (among the malicious samples): {} out of {}\".format(mcErr_m, len(mc_test)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pd.crosstab(mc_test['Label_cat'], mcPred_m, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classifier also analyzed 29502 benign samples that were incorrectly labelled as 'malicious' by the binary classifier\n",
      "Hence, this classifier was tested on 116291 samples, of which 31386 have been misclassified\n"
     ]
    }
   ],
   "source": [
    "## Note: We also accounted for the false positives of the first binary classifier (all of which have been considered as misclassifications)\n",
    "bin_falsePositives = int(bResult.fpr * len(benign_test))\n",
    "print(\"This classifier also analyzed {} benign samples that were incorrectly labelled as 'malicious' by the binary classifier\".format(bin_falsePositives))\n",
    "\n",
    "print(\"Hence, this classifier was tested on {} samples, of which {} have been misclassified\".format(len(mc_test)+bin_falsePositives, bin_falsePositives+mcErr_m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MULTI-CLASS CLASSIFIER - stand-alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing m......done! Training time: 0.017932s\tInference time: 0.094651s\n",
      "Total Misclassifications: 17414 out of 186349\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83531</td>\n",
       "      <td>1</td>\n",
       "      <td>3885</td>\n",
       "      <td>139</td>\n",
       "      <td>3193</td>\n",
       "      <td>1018</td>\n",
       "      <td>229</td>\n",
       "      <td>5032</td>\n",
       "      <td>535</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>19003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1504</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>31646</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>591</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>794</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>38</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>31718</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>536</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred      0      1     2      3     4     5    6      7    8     9\n",
       "True                                                              \n",
       "0     83531      1  3885    139  3193  1018  229   5032  535  1994\n",
       "1         0  19003     0      0     0     0    0     21    0     0\n",
       "2         8      0  1504      0     0     0    0      0    0     1\n",
       "3        40      0     6  31646     0     0    0      0    0     1\n",
       "4       142      0     1      0   203     1    0      0    0     1\n",
       "5       105      0     0      1   591     0    0     90    0    13\n",
       "6         0      0     0      0     0     0  794      0    0     0\n",
       "7        38     36     0     18     0     0   20  31718    0     0\n",
       "8         3      0     0      0     0     0    0     16  536    41\n",
       "9       192      0     0      0     2     0    0      0    0     0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We first assess its multiclassification performance, and then its binary classification performance\n",
    "\n",
    "mClf, mPred, mResult = develop_clf(all_train, all_test, features, clf_name='m', label='Label_cat', clf_type=base_clf, verbose=1)\n",
    "mErr = int(len(all_test) * (1-mResult.acc_multi))\n",
    "print(\"Total Misclassifications: {} out of {}\".format(mErr, len(all_test)))\n",
    "mResult.ctab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Misclassifications: 16553 out of 186349 (Recall: 0.993916\tFPR: 0.160973)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83531</td>\n",
       "      <td>16026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>528</td>\n",
       "      <td>86264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred      0      1\n",
       "True              \n",
       "0     83531  16026\n",
       "1       528  86264"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the binary classification performance, we use the previous predictions\n",
    "mPred_bin = np.copy(mPred)\n",
    "mPred_bin[mPred_bin > 0] = 1\n",
    "mResult.bin_results(all_test['Nature'], mPred_bin)\n",
    "mErr_bin = int(len(all_test) * (1-mResult.acc))\n",
    "\n",
    "print(\"Total Misclassifications: {} out of {} (Recall: {:5f}\\tFPR: {:5f})\".format(mErr_bin, len(all_test), mResult.rec, mResult.fpr))\n",
    "mResult.ctab_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENSEMBLE CLASSIFIERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training \"individual\" binary classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing ddos......done! Training time: 0.004982s\tInference time: 0.061793s\n",
      "Testing ddos...\n",
      "...done! \tInference time: 0.091693s\n",
      "Training and testing geye......done! Training time: 0.004984s\tInference time: 0.054816s\n",
      "Testing geye...\n",
      "...done! \tInference time: 0.084718s\n",
      "Training and testing hulk......done! Training time: 0.004989s\tInference time: 0.082687s\n",
      "Testing hulk...\n",
      "...done! \tInference time: 0.084795s\n",
      "Training and testing http......done! Training time: 0.004946s\tInference time: 0.047841s\n",
      "Testing http...\n",
      "...done! \tInference time: 0.083690s\n",
      "Training and testing loris......done! Training time: 0.006015s\tInference time: 0.063755s\n",
      "Testing loris...\n",
      "...done! \tInference time: 0.090018s\n",
      "Training and testing ftp......done! Training time: 0.004983s\tInference time: 0.048836s\n",
      "Testing ftp...\n",
      "...done! \tInference time: 0.083720s\n",
      "Training and testing pscan......done! Training time: 0.004987s\tInference time: 0.062785s\n",
      "Testing pscan...\n",
      "...done! \tInference time: 0.083724s\n",
      "Training and testing ssh......done! Training time: 0.004002s\tInference time: 0.047819s\n",
      "Testing ssh...\n",
      "...done! \tInference time: 0.082688s\n",
      "Training and testing other......done! Training time: 0.005099s\tInference time: 0.048758s\n",
      "Testing other...\n",
      "...done! \tInference time: 0.084747s\n",
      "Total training time: 0.044986s\t AvgFPR: 0.057736\t AvgTPR: 0.986704\tTotal inference time: 0.769794s (fake: 0.519091s)\n"
     ]
    }
   ],
   "source": [
    "ensemble_df = pd.DataFrame()\n",
    "\n",
    "benign_train = benign_df[benign_df['is_train']==True]\n",
    "benign_test = benign_df[benign_df['is_test']==True]\n",
    "\n",
    "\n",
    "ens_time = 0\n",
    "ens_avgFPR = 0\n",
    "tot_TP = 0\n",
    "tot_P = 0\n",
    "ens_infer_time = 0\n",
    "fakeEns_infer_time = 0\n",
    "\n",
    "for a in attack_names:\n",
    "    exec(f\"{a}_train = {a}_df[{a}_df['is_train']==True]\")\n",
    "    exec(f\"{a}_test = {a}_df[{a}_df['is_test']==True]\")\n",
    "\n",
    "    exec(f\"train = pd.concat([benign_train, {a}_train])\")\n",
    "    exec(f\"test = pd.concat([benign_test, {a}_test])\")\n",
    "    \n",
    "    # We first train a classifier only on \"benign\" or on malicious samples of a specific attack. \n",
    "    # Afterwards, we immediately test it on a test-set having ONLY malicious samples of this specific attack\n",
    "    # Note: such \"testing\" is redundant, because it assumes that the classifier only receives the samples of the attack it is trained on!\n",
    "    exec(f\"{a}Clf, {a}Pred, {a}Result = develop_clf(train, test, features, clf_name='{a}', clf_type=base_clf, verbose=1)\")\n",
    "    exec(f\"fakeEns_infer_time += {a}Result.infer_time\")\n",
    "    # We now test the specific classifier on the ENTIRE test-set, thereby allowing to assess its performance also against malicious samples of different attacks\n",
    "    exec(f\"{a}_allPred, {a}_allResults, {a}Result.infer_time = evaluate_clf({a}Clf, all_test, features, clf_name='{a}', time={a}Result.time, verbose=1)\")\n",
    "\n",
    "    exec(f\"ensemble_df['{a}'] = {a}_allPred\")\n",
    "\n",
    "    exec(f\"tot_TP += ({a}Result.rec * len({a}_test))\")\n",
    "    exec(f\"tot_P += len({a}_test)\")\n",
    "\n",
    "\n",
    "    exec(f\"ens_avgFPR += {a}Result.fpr\")\n",
    "    exec(f\"ens_time += {a}Result.time\")\n",
    "    exec(f\"ens_infer_time +={a}Result.infer_time\")\n",
    "\n",
    "ens_avgFPR = ens_avgFPR / len(attack_names)\n",
    "ens_avgREC = tot_TP/tot_P\n",
    "\n",
    "print(\"Total training time: {:5f}s\\t AvgFPR: {:5f}\\t AvgTPR: {:5f}\\tTotal inference time: {:5f}s (fake: {:5f}s)\".\n",
    "      format(ens_time, ens_avgFPR, ens_avgREC, ens_infer_time, fakeEns_infer_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble (real assessment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we measure the combined performance of the entire ensemble\n",
    "# This is done with a logical or, or for majority voting (regulated by the \"agreement\" variable)\n",
    "\n",
    "ensemble_df[\"sum\"] = ensemble_df.sum(axis=1)\n",
    "#calculating \n",
    "ensemble_df[\"LOR\"] = (ensemble_df[\"sum\"]>0)\n",
    "\n",
    "#Appending Ground Truth\n",
    "temp = all_test['Nature'] #> 0)\n",
    "ensemble_df['True'] = ((temp.reset_index(drop=True)) > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble: Logical OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Misclassifications: 27528 out of 186349 (Recall: 0.997627\tFPR: 0.274436)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>72235</td>\n",
       "      <td>27322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>206</td>\n",
       "      <td>86586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred   False  True \n",
       "True               \n",
       "False  72235  27322\n",
       "True     206  86586"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enslorResult = Result(ensemble_df['True'], ensemble_df['LOR'], ens_time, ens_infer_time)\n",
    "enslorErr= int(len(all_test) * (1-enslorResult.acc))\n",
    "\n",
    "print(\"Total Misclassifications: {} out of {} (Recall: {:5f}\\tFPR: {:5f})\".format(enslorErr, len(all_test), enslorResult.rec, enslorResult.fpr))\n",
    "enslorResult.ctab_bin # you can also try with enslorResult.ctab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble: Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting: at least 5 out of 9 classifiers must agree that a sample is malicious.\n",
      "Total Misclassifications: 36486 out of 186349 (Recall: 0.597256\tFPR: 0.015378)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>98026</td>\n",
       "      <td>1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>34955</td>\n",
       "      <td>51837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred   False  True \n",
       "True               \n",
       "False  98026   1531\n",
       "True   34955  51837"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_agree = math.ceil(agreement * len(attack_names))\n",
    "print(\"Voting: at least {} out of {} classifiers must agree that a sample is malicious.\".format(min_agree, len(attack_names)))\n",
    "ensemble_df[\"MAJV\"] = (ensemble_df[\"sum\"]>=min_agree)\n",
    "ensvotResult = Result(ensemble_df['True'], ensemble_df['MAJV'], ens_time, ens_infer_time)\n",
    "ensvotErr = int(len(all_test) * (1-ensvotResult.acc))\n",
    "print(\"Total Misclassifications: {} out of {} (Recall: {:5f}\\tFPR: {:5f})\".format(ensvotErr, len(all_test), ensvotResult.rec, ensvotResult.fpr))\n",
    "ensvotResult.ctab_bin # you can also try with ensvotResult.ctab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble: Stacked Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Misclassifications: 18845 out of 186349 (Recall: 0.995207\tFPR: 0.185120)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81127</td>\n",
       "      <td>18430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>416</td>\n",
       "      <td>86376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred      0      1\n",
       "True              \n",
       "0     81127  18430\n",
       "1       416  86376"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.classifier import StackingClassifier\n",
    "clf_list = []\n",
    "for a in attack_names:\n",
    "    exec(f\"clf_list.append({a}Clf)\")\n",
    "\n",
    "meta = choose_clf(clf_type=base_clf)\n",
    "sClf = StackingClassifier(classifiers=clf_list, meta_classifier=meta, fit_base_estimators=False, use_probas = False)\n",
    "s_timeStart = time.time()\n",
    "sClf.fit(all_train[features], all_train['Nature'])\n",
    "s_time = time.time() - s_timeStart + ens_time\n",
    "s_timeStart = time.time()\n",
    "sPred = sClf.predict(all_test[features])\n",
    "s_infer_time = time.time()-s_timeStart\n",
    "sResult = Result(all_test['Nature'], sPred, s_time, s_infer_time)\n",
    "if sResult.acc < sResult.acc_multi:\n",
    "    sResult.acc = sResult.acc_multi\n",
    "sErr = int(len(all_test) * (1-sResult.acc))\n",
    "print(\"Total Misclassifications: {} out of {} (Recall: {:5f}\\tFPR: {:5f})\".format(sErr, len(all_test), sResult.rec, sResult.fpr))\n",
    "\n",
    "sResult.ctab_bin # you can also try with sResult.ctab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open World Assessment: One attack against all classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open World assessment: performance against one unknown attack (averaged for all attacks in the dataset)\n",
      "      Binary CLF: TPR=0.731778\tFPR=0.289414\n",
      "      Multiclass (binarized) CLF: TPR=0.668178\tFPR=0.171463\n",
      "      EnsLOR CLF: TPR=0.816140\tFPR=0.258750\n",
      "      EnsVOT CLF: TPR=0.175645\tFPR=0.010300\n",
      "      EnsSTK CLF: TPR=0.815693\tFPR=0.181915\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "### The following code is a mixture of everything described insofar.\n",
    "### We are only focused on TPR and FPR here. We do not care about accuracy, adversarial robustness, or runtime.\n",
    "### These experiments are also done only on the \"Complete\" feature set\n",
    "\n",
    "\n",
    "oaac_bin_rec = 0\n",
    "oaac_bin_fpr = 0\n",
    "oaac_multi_rec = 0\n",
    "oaac_multi_fpr = 0\n",
    "oaac_enslor_rec = 0\n",
    "oaac_enslor_fpr = 0\n",
    "oaac_ensvot_rec = 0\n",
    "oaac_ensvot_fpr = 0\n",
    "oaac_ensstk_rec = 0\n",
    "oaac_ensstk_fpr = 0\n",
    "\n",
    "for u in attack_names: # u is the unknown attack\n",
    "    #print(u) # this is the unknown attack\n",
    "    #exec(f\"{u}_test = {u}_df[{u}_df['is_train']==False]\") # create test set by putting the \"test\" samples of u\n",
    "    exec(f\"{u}_test = pd.concat([benign_test, {u}_test])\") # add to the test set the \"benign\" test samples\n",
    "    exec(f\"{u}_train = benign_df[benign_df['is_train']==True]\") # compose the \"training\" set: start by putting the benign \"training\" samples\n",
    "    for a in attack_names: \n",
    "        # for every attack that is not u, add its training samples to the training set of u\n",
    "        if a==u:\n",
    "            continue\n",
    "        exec(f\"{u}_train = pd.concat([{u}_train, {a}_df[{a}_df['is_train']==True]])\")\n",
    "\n",
    "\n",
    "    # We have created the training and testing set. Now we must train and test a binary classifier by following the standard procedure\n",
    "    ########## BINARY CLASSIFIER ##########\n",
    "    exec(f\"{u}_oaac_bClf, {u}_oaac_bPred, {u}_oaac_bResult = develop_clf({u}_train, {u}_test, features, clf_name='{u}_oaac_bin', label='Nature', clf_type=base_clf)\")\n",
    "\n",
    "\n",
    "    ########## Multiclass CLASSIFIER ########## --> Train, then test only on binary\n",
    "    exec(f\"{u}_oaac_mClf, {u}_oaac_mPred, {u}_oaac_mResult = develop_clf({u}_train, {u}_test, features, clf_name='{u}_oaac_multi', label='Label_cat', clf_type=base_clf)\")\n",
    "    exec(f\"{u}_oaac_mPred_bin = np.copy({u}_oaac_mPred)\")\n",
    "    exec(f\"{u}_oaac_mPred_bin[{u}_oaac_mPred_bin > 0] = 1\")\n",
    "    exec(f\"{u}_oaac_mResult.bin_results({u}_test['Nature'], {u}_oaac_mPred_bin)\")\n",
    "\n",
    "\n",
    "    ######### Ensemble ##############\n",
    "    # send the samples in TEST to all the classifiers of the ensemble (which are already trained), aside from the one focusing on u\n",
    "    exec(f\"{u}_oaac_ens_df = pd.DataFrame()\")\n",
    "    for a in attack_names:    \n",
    "        if a==u:\n",
    "                continue\n",
    "        exec(f\"{a}_{u}Pred, {a}_{u}Results, {a}_{u}_infer_time = evaluate_clf({a}Clf, {u}_test, features, clf_name='{a}_{u}', time={a}Result.time)\")\n",
    "        exec(f\"{u}_oaac_ens_df['{a}'] = {a}_{u}Pred\")\n",
    "\n",
    "    # now we have the dataframe with all the predictions, let's see the aggregate results\n",
    "    exec(f\"{u}_oaac_ens_df['sum'] = {u}_oaac_ens_df.sum(axis=1)\")\n",
    "    exec(f\"{u}_oaac_ens_df['LOR'] = ({u}_oaac_ens_df['sum']>0)\")\n",
    "    exec(f\"temp = {u}_test['Nature'] #> 0)\")\n",
    "    exec(f\"{u}_oaac_ens_df['True'] = ((temp.reset_index(drop=True)) > 0)\")\n",
    "    exec(f\"{u}_oaac_enslorResult = Result({u}_oaac_ens_df['True'], {u}_oaac_ens_df['LOR'], (ens_time-{u}Result.time), (ens_infer_time-{u}Result.infer_time))\")\n",
    "\n",
    "    # now we consider the majority voting of the ensemble\n",
    "    exec(f\"{u}_oaac_ens_df['MAJV'] = ({u}_oaac_ens_df['sum']>=min_agree)\")\n",
    "    exec(f\"{u}_oaac_ensvotResult = Result({u}_oaac_ens_df['True'], {u}_oaac_ens_df['MAJV'], (ens_time-{u}Result.time), (ens_infer_time-{u}Result.infer_time))\")\n",
    "\n",
    "    # finally, let's use the stacking ensemble\n",
    "    exec(f\"{u}_clf_list = []\")\n",
    "    for a in attack_names:\n",
    "        if a==u:\n",
    "                continue\n",
    "        exec(f\"{u}_clf_list.append({a}Clf)\")\n",
    "    exec(f\"{u}_oaac_sClf = StackingClassifier(classifiers={u}_clf_list, meta_classifier=meta, fit_base_estimators=False, use_probas = False)\")\n",
    "    exec(f\"{u}_oaac_sClf.fit({u}_train[features], {u}_train['Nature'])\")\n",
    "    exec(f\"{u}_oaac_sPred = {u}_oaac_sClf.predict({u}_test[features])\")\n",
    "    exec(f\"{u}_oaac_sResult = Result({u}_test['Nature'], {u}_oaac_sPred, (ens_time-{u}Result.time), (ens_infer_time-{u}Result.infer_time))\")\n",
    "\n",
    "    # Updating results\n",
    "    exec(f\"oaac_bin_rec += {u}_oaac_bResult.rec\")\n",
    "    exec(f\"oaac_bin_fpr += {u}_oaac_bResult.fpr\")\n",
    "    exec(f\"oaac_multi_rec += {u}_oaac_mResult.rec\")\n",
    "    exec(f\"oaac_multi_fpr += {u}_oaac_mResult.fpr\")\n",
    "    exec(f\"oaac_enslor_rec += {u}_oaac_enslorResult.rec\")\n",
    "    exec(f\"oaac_enslor_fpr += {u}_oaac_enslorResult.fpr\")\n",
    "    exec(f\"oaac_ensvot_rec += {u}_oaac_ensvotResult.rec\")\n",
    "    exec(f\"oaac_ensvot_fpr += {u}_oaac_ensvotResult.fpr\")\n",
    "    exec(f\"oaac_ensstk_rec += {u}_oaac_sResult.rec\")\n",
    "    exec(f\"oaac_ensstk_fpr += {u}_oaac_sResult.fpr\")\n",
    "\n",
    "# Finalizing averages\n",
    "oaac_bin_rec /= len(attack_names)\n",
    "oaac_bin_fpr /= len(attack_names)\n",
    "oaac_multi_rec /= len(attack_names)\n",
    "oaac_multi_fpr /= len(attack_names)\n",
    "oaac_enslor_rec /= len(attack_names)\n",
    "oaac_enslor_fpr /= len(attack_names)\n",
    "oaac_ensvot_rec /= len(attack_names)\n",
    "oaac_ensvot_fpr /= len(attack_names)\n",
    "oaac_ensstk_rec /= len(attack_names)\n",
    "oaac_ensstk_fpr /= len(attack_names)\n",
    "\n",
    "\n",
    "print('''Open World assessment: performance against one unknown attack (averaged for all attacks in the dataset)\n",
    "      Binary CLF: TPR={:5f}\\tFPR={:5f}\n",
    "      Multiclass (binarized) CLF: TPR={:5f}\\tFPR={:5f}\n",
    "      EnsLOR CLF: TPR={:5f}\\tFPR={:5f}\n",
    "      EnsVOT CLF: TPR={:5f}\\tFPR={:5f}\n",
    "      EnsSTK CLF: TPR={:5f}\\tFPR={:5f}\n",
    "      '''.format(oaac_bin_rec, oaac_bin_fpr,\n",
    "                 oaac_multi_rec, oaac_multi_fpr,\n",
    "                 oaac_enslor_rec, oaac_enslor_fpr,\n",
    "                 oaac_ensvot_rec, oaac_ensvot_fpr,\n",
    "                 oaac_ensstk_rec, oaac_ensstk_fpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessment on Essential feature set (and Adversarial attacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BINARY CLASSIFIER (Essential features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing adv_bin......done! Training time: 0.006977s\tInference time: 0.041860s\n",
      "Total Misclassifications: 33682 out of 186349 (Recall: 0.993698\tFPR: 0.332824)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66422</td>\n",
       "      <td>33135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>547</td>\n",
       "      <td>86245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred      0      1\n",
       "True              \n",
       "0     66422  33135\n",
       "1       547  86245"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sma_bClf, sma_bPred, sma_bResult = develop_clf(all_train, all_test, small_features, clf_name='adv_bin', label='Nature', clf_type=base_clf, verbose=1)\n",
    "sma_bErr = int(len(all_test) * (1-sma_bResult.acc))\n",
    "if (sma_bResult.acc == 0):\n",
    "    sma_bErr = int(len(all_test) * (1-sma_bResult.acc_multi))\n",
    "else:\n",
    "    sma_bErr = int(len(all_test) * (1-sma_bResult.acc))\n",
    "\n",
    "print(\"Total Misclassifications: {} out of {} (Recall: {:5f}\\tFPR: {:5f})\".format(sma_bErr, len(all_test), sma_bResult.rec, sma_bResult.fpr))\n",
    "pd.crosstab(all_test['Nature'], sma_bPred, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adversarial Attack against Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial Recall (baseline): 0.994\n",
      "Adversarial Recall (attack): 1.000\n"
     ]
    }
   ],
   "source": [
    "# Note that the adversarial attacks only affect a subset of the initial set of malicious samples\n",
    "# Hence, we compute the classification performance also on this subset for a far comparison\n",
    "\n",
    "\n",
    "\n",
    "adv_bPred_base = sma_bClf.predict(mal_base[small_features])\n",
    "adv_bPred_adv = sma_bClf.predict(mal_adv[small_features])\n",
    "adv_bin_base_rec =  recall_score(mal_base['Nature'], adv_bPred_base, pos_label=1)\n",
    "adv_bin_adv_rec = recall_score(mal_adv['Nature'], adv_bPred_adv, pos_label=1)\n",
    "\n",
    "print(\"Adversarial Recall (baseline): {:.3f}\".format(adv_bin_base_rec))\n",
    "print(\"Adversarial Recall (attack): {:.3f}\".format(adv_bin_adv_rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Classifier - cascade (essential feature set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing sma_mc......done! Training time: 0.005980s\tInference time: 0.016951s\n",
      "Total Misclassifications: 1800 out of 86792\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1513</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31614</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>297</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>218</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>794</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred      1     2      3    4    5    6      7    9\n",
       "True                                               \n",
       "1     19002     0      0    0    0    0     22    0\n",
       "2         0  1513      0    0    0    0      0    0\n",
       "3         0     1  31614   10    0    0      0   68\n",
       "4         0     0      0  176  161    0      0   11\n",
       "5       208     0      0  297   75    0    218    2\n",
       "6         0     0      0    0    0  794      0    0\n",
       "7       131     0      0    0    0    0  31699    0\n",
       "8         0    11      0    0    0    1     16  568\n",
       "9         0     0      0    0    0    0     75  119"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sma_mcClf, sma_mcPred, sma_mcResult = develop_clf(malicious_train, malicious_test, small_features, clf_name='sma_mc', label='Label_cat', clf_type=base_clf, verbose=1)\n",
    "sma_mcErr = int(len(malicious_test) * (1-sma_mcResult.acc_multi))\n",
    "\n",
    "print(\"Total Misclassifications: {} out of {}\".format(sma_mcErr, len(malicious_test)))\n",
    "pd.crosstab(malicious_test['Label_cat'], sma_mcPred, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Misclassifications (among the malicious samples): 1366 out of 86245\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1513</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31614</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>297</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>794</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31696</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred      1     2      3    4    5    6      7    9\n",
       "True                                               \n",
       "1     19002     0      0    0    0    0     22    0\n",
       "2         0  1513      0    0    0    0      0    0\n",
       "3         0     1  31614   10    0    0      0   68\n",
       "4         0     0      0  169  158    0      0   11\n",
       "5         0     0      0  297   75    0    128    2\n",
       "6         0     0      0    0    0  794      0    0\n",
       "7        73     0      0    0    0    0  31696    0\n",
       "8         0    11      0    0    0    1     16  568\n",
       "9         0     0      0    0    0    0      0   16"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We select the samples flagged as malicious by the initial classifier.\n",
    "# Of course, samples flagged as malicious that are NOT actually malicious will always be misclassified\n",
    "\n",
    "all_test['sma_bPred'] = sma_bPred\n",
    "sma_mc_test = all_test[(all_test['sma_bPred']==1) & (all_test['Nature']==1)]\n",
    "if (len(sma_mc_test)==0):\n",
    "    # in this case, this classifier receives nothing\n",
    "    print(\"There is no malicious sample flagged as malicious to analyze!\")\n",
    "\n",
    "sma_mcPred_m = sma_mcClf.predict(sma_mc_test[small_features])\n",
    "sma_mcResult.acc_multic = accuracy_score(sma_mc_test['Label_cat'], sma_mcPred_m, normalize=True, sample_weight=None)\n",
    "sma_mcErr_m = int((1-sma_mcResult.acc_multic) * len(sma_mc_test))\n",
    "print(\"Total Misclassifications (among the malicious samples): {} out of {}\".format(sma_mcErr_m, len(sma_mc_test)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pd.crosstab(sma_mc_test['Label_cat'], sma_mcPred_m, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classifier also analyzed 33135 benign samples that were incorrectly labelled as 'malicious' by the (small) binary classifier\n",
      "Hence, this (small) classifier was tested on 119380 samples, of which 34501 have been misclassified\n"
     ]
    }
   ],
   "source": [
    "## Note: We also accounted for the false positives of the first binary classifier (all of which have been considered as misclassifications)\n",
    "sma_bin_falsePositives = int(sma_bResult.fpr * len(benign_test))\n",
    "print(\"This classifier also analyzed {} benign samples that were incorrectly labelled as 'malicious' by the (small) binary classifier\".format(sma_bin_falsePositives))\n",
    "\n",
    "print(\"Hence, this (small) classifier was tested on {} samples, of which {} have been misclassified\".format(len(sma_mc_test)+sma_bin_falsePositives, sma_bin_falsePositives+sma_mcErr_m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Classifier - stand-alone (essential feature set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing sma_m......done! Training time: 0.005989s\tInference time: 0.044887s\n",
      "Total Misclassifications: 29965 out of 186349\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72237</td>\n",
       "      <td>44</td>\n",
       "      <td>814</td>\n",
       "      <td>4071</td>\n",
       "      <td>2532</td>\n",
       "      <td>3254</td>\n",
       "      <td>4307</td>\n",
       "      <td>4275</td>\n",
       "      <td>15</td>\n",
       "      <td>8008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>19002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1513</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>30940</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>127</td>\n",
       "      <td>336</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>296</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>793</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>31736</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred      0      1     2      3     4     5     6      7   8     9\n",
       "True                                                              \n",
       "0     72237     44   814   4071  2532  3254  4307   4275  15  8008\n",
       "1         0  19002     0      0     0     0     0     22   0     0\n",
       "2         0      0  1513      0     0     0     0      0   0     0\n",
       "3        12      0   327  30940     3     0     0      0   0   411\n",
       "4       151      0     9     18   160     1     0      0   0     9\n",
       "5       127    336     0      0   296     2     0      1   0    38\n",
       "6         0      0     0      0     0     1   793      0   0     0\n",
       "7        21     36     0     18     0     0    19  31736   0     0\n",
       "8         3      0     2      0     0    14     0     15   0   562\n",
       "9       194      0     0      0     0     0     0      0   0     0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sma_mClf, sma_mPred, sma_mResult = develop_clf(all_train, all_test, small_features, clf_name='sma_m', label='Label_cat', clf_type=base_clf, verbose=1)\n",
    "sma_mErr = int(len(all_test) * (1-sma_mResult.acc_multi))\n",
    "\n",
    "print(\"Total Misclassifications: {} out of {}\".format(sma_mErr, len(all_test)))\n",
    "sma_mResult.ctab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiclass Classifier: Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Misclassifications: 27828 out of 186349 (Recall: 0.994147\tFPR: 0.274416)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72237</td>\n",
       "      <td>27320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>508</td>\n",
       "      <td>86284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred      0      1\n",
       "True              \n",
       "0     72237  27320\n",
       "1       508  86284"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########## MULTI-CLASS CLASSIFIER - BINARY ##########\n",
    "sma_mPred_bin = np.copy(sma_mPred)\n",
    "sma_mPred_bin[sma_mPred_bin > 0] = 1\n",
    "sma_mResult.bin_results(all_test['Nature'], sma_mPred_bin)\n",
    "sma_mErr_bin = int(len(all_test) * (1-sma_mResult.acc))\n",
    "\n",
    "print(\"Total Misclassifications: {} out of {} (Recall: {:5f}\\tFPR: {:5f})\".format(sma_mErr_bin, len(all_test), sma_mResult.rec, sma_mResult.fpr))\n",
    "sma_mResult.ctab_bin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adversarial Attack against the Multiclass Classifier (binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial Recall (baseline): 0.994\n",
      "Adversarial Recall (attack): 0.904\n"
     ]
    }
   ],
   "source": [
    "adv_mPred_base = sma_mClf.predict(mal_base[small_features])\n",
    "adv_mPred_adv = sma_mClf.predict(mal_adv[small_features])\n",
    "\n",
    "adv_mPred_base_bin = np.copy(adv_mPred_base)\n",
    "adv_mPred_base_bin[adv_mPred_base_bin > 0] = 1\n",
    "\n",
    "adv_mPred_adv_bin = np.copy(adv_mPred_adv)\n",
    "adv_mPred_adv_bin[adv_mPred_adv_bin > 0] = 1\n",
    "\n",
    "\n",
    "adv_multi_base_rec =  recall_score(mal_base['Nature'], adv_mPred_base_bin)\n",
    "adv_multi_adv_rec = recall_score(mal_adv['Nature'], adv_mPred_adv_bin)\n",
    "\n",
    "print(\"Adversarial Recall (baseline): {:.3f}\".format(adv_multi_base_rec))\n",
    "print(\"Adversarial Recall (attack): {:.3f}\".format(adv_multi_adv_rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Classifiers (essential feature set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing sma_ddos......done! Training time: 0.004899s\tInference time: 0.025922s\n",
      "Testing sma_ddos...\n",
      "...done! \tInference time: 0.033895s\n",
      "Training and testing sma_geye......done! Training time: 0.003986s\tInference time: 0.020939s\n",
      "Testing sma_geye...\n",
      "...done! \tInference time: 0.032804s\n",
      "Training and testing sma_hulk......done! Training time: 0.003982s\tInference time: 0.026902s\n",
      "Testing sma_hulk...\n",
      "...done! \tInference time: 0.032968s\n",
      "Training and testing sma_http......done! Training time: 0.003978s\tInference time: 0.019943s\n",
      "Testing sma_http...\n",
      "...done! \tInference time: 0.033958s\n",
      "Training and testing sma_loris......done! Training time: 0.003978s\tInference time: 0.017950s\n",
      "Testing sma_loris...\n",
      "...done! \tInference time: 0.032884s\n",
      "Training and testing sma_ftp......done! Training time: 0.003986s\tInference time: 0.041939s\n",
      "Testing sma_ftp...\n",
      "...done! \tInference time: 0.031901s\n",
      "Training and testing sma_pscan......done! Training time: 0.003990s\tInference time: 0.025906s\n",
      "Testing sma_pscan...\n",
      "...done! \tInference time: 0.031888s\n",
      "Training and testing sma_ssh......done! Training time: 0.004991s\tInference time: 0.017939s\n",
      "Testing sma_ssh...\n",
      "...done! \tInference time: 0.035412s\n",
      "Training and testing sma_other......done! Training time: 0.004981s\tInference time: 0.017299s\n",
      "Testing sma_other...\n",
      "...done! \tInference time: 0.031891s\n",
      "Total training time: 0.038772s\t AvgFPR: 0.081228\t AvgTPR: 0.989538\tTotal inference time: 0.297600s (fake: 0.214739s)\n"
     ]
    }
   ],
   "source": [
    "sma_ensemble_df = pd.DataFrame()\n",
    "adv_ensemble_df_base = pd.DataFrame()\n",
    "adv_ensemble_df_adv = pd.DataFrame()\n",
    "\n",
    "benign_train = benign_df[benign_df['is_train']==True]\n",
    "benign_test = benign_df[benign_df['is_test']==True]\n",
    "\n",
    "\n",
    "sma_ens_time = 0\n",
    "sma_ens_avgFPR = 0\n",
    "sma_tot_TP = 0\n",
    "sma_tot_P = 0\n",
    "sma_ens_infer_time = 0\n",
    "sma_fakeEns_infer_time = 0\n",
    "\n",
    "for a in attack_names:\n",
    "    exec(f\"{a}_train = {a}_df[{a}_df['is_train']==True]\")\n",
    "    exec(f\"{a}_test = {a}_df[{a}_df['is_test']==True]\")\n",
    "\n",
    "    exec(f\"train = pd.concat([benign_train, {a}_train])\")\n",
    "    exec(f\"test = pd.concat([benign_test, {a}_test])\")\n",
    "\n",
    "    exec(f\"sma_{a}Clf, sma_{a}Pred, sma_{a}Result = develop_clf(train, test, small_features, clf_name='sma_{a}', clf_type=base_clf, verbose=1)\")\n",
    "    exec(f\"sma_fakeEns_infer_time += sma_{a}Result.infer_time\")\n",
    "    \n",
    "    exec(f\"sma_{a}_allPred, sma_{a}_allResults, sma_{a}Result.infer_time = evaluate_clf(sma_{a}Clf, all_test, small_features, clf_name='sma_{a}', time=sma_{a}Result.time, verbose=1)\")\n",
    "    exec(f\"sma_ensemble_df['{a}'] = sma_{a}_allPred\")\n",
    "\n",
    "    exec(f\"adv_{a}Pred_base = sma_{a}Clf.predict(mal_base[small_features])\")\n",
    "    exec(f\"adv_{a}Pred_adv = sma_{a}Clf.predict(mal_adv[small_features])\")\n",
    "    exec(f\"adv_ensemble_df_base['{a}'] = adv_{a}Pred_base\")\n",
    "    exec(f\"adv_ensemble_df_adv['{a}'] = adv_{a}Pred_adv\")\n",
    "\n",
    "\n",
    "\n",
    "    exec(f\"sma_tot_TP += (sma_{a}Result.rec * len({a}_test))\")\n",
    "    exec(f\"sma_tot_P += len({a}_test)\")\n",
    "\n",
    "\n",
    "    exec(f\"sma_ens_avgFPR += sma_{a}Result.fpr\")\n",
    "    exec(f\"sma_ens_time += sma_{a}Result.time\")\n",
    "    exec(f\"sma_ens_infer_time +=sma_{a}Result.infer_time\")\n",
    "\n",
    "\n",
    "\n",
    "sma_ens_avgFPR = sma_ens_avgFPR / len(attack_names)\n",
    "sma_ens_avgREC = sma_tot_TP/sma_tot_P\n",
    "\n",
    "\n",
    "print(\"Total training time: {:5f}s\\t AvgFPR: {:5f}\\t AvgTPR: {:5f}\\tTotal inference time: {:5f}s (fake: {:5f}s)\".\n",
    "      format(sma_ens_time, sma_ens_avgFPR, sma_ens_avgREC, sma_ens_infer_time, sma_fakeEns_infer_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing real Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sma_ensemble_df[\"sum\"] = sma_ensemble_df.sum(axis=1)\n",
    "sma_ensemble_df[\"LOR\"] = (sma_ensemble_df[\"sum\"]>0)\n",
    "temp = all_test['Nature'] \n",
    "sma_ensemble_df['True'] = ((temp.reset_index(drop=True)) > 0)\n",
    "\n",
    "adv_ensemble_df_base[\"sum\"] = adv_ensemble_df_base.sum(axis=1)\n",
    "adv_ensemble_df_base[\"LOR\"] = (adv_ensemble_df_base[\"sum\"]>0)\n",
    "temp = mal_base['Nature']\n",
    "adv_ensemble_df_base['True'] = ((temp.reset_index(drop=True)) > 0)\n",
    "\n",
    "\n",
    "adv_ensemble_df_adv[\"sum\"] = adv_ensemble_df_adv.sum(axis=1)\n",
    "adv_ensemble_df_adv[\"LOR\"] = (adv_ensemble_df_adv[\"sum\"]>0)\n",
    "temp = mal_adv['Nature']\n",
    "adv_ensemble_df_adv['True'] = ((temp.reset_index(drop=True)) > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble: Logical OR (essential feature set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Misclassifications: 32788 out of 186349 (Recall: 0.997166\tFPR: 0.326868)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>67015</td>\n",
       "      <td>32542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>246</td>\n",
       "      <td>86546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred   False  True \n",
       "True               \n",
       "False  67015  32542\n",
       "True     246  86546"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sma_enslorResult = Result(sma_ensemble_df['True'], sma_ensemble_df['LOR'], sma_ens_time, sma_ens_infer_time)\n",
    "sma_enslorErr= int(len(all_test) * (1-sma_enslorResult.acc))\n",
    "\n",
    "print(\"Total Misclassifications: {} out of {} (Recall: {:5f}\\tFPR: {:5f})\".format(sma_enslorErr, len(all_test), sma_enslorResult.rec, sma_enslorResult.fpr))\n",
    "sma_enslorResult.ctab_bin # you can also try with sma_enslorResult.ctab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logical OR: Adversarial Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial Recall (baseline): 0.997\n",
      "Adversarial Recall (attack): 0.625\n"
     ]
    }
   ],
   "source": [
    "adv_enslor_base_rec = recall_score(mal_base['Nature'], adv_ensemble_df_base[\"LOR\"])\n",
    "adv_enslor_adv_rec = recall_score(mal_adv['Nature'], adv_ensemble_df_adv[\"LOR\"])\n",
    "\n",
    "print(\"Adversarial Recall (baseline): {:.3f}\".format(adv_enslor_base_rec))\n",
    "print(\"Adversarial Recall (attack): {:.3f}\".format(adv_enslor_adv_rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble: Majority Voting (essential feature set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Misclassifications: 68525 out of 186349 (Recall: 0.238686\tFPR: 0.024599)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>97108</td>\n",
       "      <td>2449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>66076</td>\n",
       "      <td>20716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred   False  True \n",
       "True               \n",
       "False  97108   2449\n",
       "True   66076  20716"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sma_ensemble_df[\"MAJV\"] = (sma_ensemble_df[\"sum\"]>=min_agree)\n",
    "sma_ensvotResult = Result(sma_ensemble_df['True'], sma_ensemble_df['MAJV'], sma_ens_time, sma_ens_infer_time)\n",
    "sma_ensvotErr = int(len(all_test) * (1-sma_ensvotResult.acc))\n",
    "\n",
    "print(\"Total Misclassifications: {} out of {} (Recall: {:5f}\\tFPR: {:5f})\".format(sma_ensvotErr, len(all_test), sma_ensvotResult.rec, sma_ensvotResult.fpr))\n",
    "sma_ensvotResult.ctab_bin # you can also try with sma_ensvotResult.ctab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Majority Voting: Adversarial Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial Recall (baseline): 0.239\n",
      "Adversarial Recall (attack): 0.000\n"
     ]
    }
   ],
   "source": [
    "adv_ensemble_df_base[\"MAJV\"] = (adv_ensemble_df_base[\"sum\"]>=min_agree)\n",
    "adv_ensemble_df_adv[\"MAJV\"] = (adv_ensemble_df_adv[\"sum\"]>=min_agree)\n",
    "\n",
    "adv_ensvot_base_rec = recall_score(mal_base['Nature'], adv_ensemble_df_base[\"MAJV\"])\n",
    "adv_ensvot_adv_rec = recall_score(mal_adv['Nature'], adv_ensemble_df_adv[\"MAJV\"])\n",
    "\n",
    "print(\"Adversarial Recall (baseline): {:.3f}\".format(adv_ensvot_base_rec))\n",
    "print(\"Adversarial Recall (attack): {:.3f}\".format(adv_ensvot_adv_rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble: Stacked Classifier (essential feature set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Misclassifications: 32464 out of 186349 (Recall: 0.997166\tFPR: 0.323624)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67338</td>\n",
       "      <td>32219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>246</td>\n",
       "      <td>86546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred      0      1\n",
       "True              \n",
       "0     67338  32219\n",
       "1       246  86546"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_list = []\n",
    "for a in attack_names:\n",
    "    exec(f\"clf_list.append(sma_{a}Clf)\")\n",
    "\n",
    "sma_sClf = StackingClassifier(classifiers=clf_list, meta_classifier=meta, fit_base_estimators=False, use_probas = False)\n",
    "s_timeStart = time.time()\n",
    "sma_sClf.fit(all_train[small_features], all_train['Nature'])\n",
    "sma_s_time = time.time() - s_timeStart + sma_ens_time\n",
    "s_timeStart = time.time()\n",
    "sma_sPred = sma_sClf.predict(all_test[small_features])\n",
    "sma_s_infer_time = time.time()-s_timeStart\n",
    "sma_sResult = Result(all_test['Nature'], sma_sPred, sma_s_time, sma_s_infer_time)\n",
    "if sma_sResult.acc < sma_sResult.acc_multi:\n",
    "    sma_sResult.acc = sma_sResult.acc_multi\n",
    "sma_sErr = int(len(all_test) * (1-sma_sResult.acc))\n",
    "\n",
    "print(\"Total Misclassifications: {} out of {} (Recall: {:5f}\\tFPR: {:5f})\".format(sma_sErr, len(all_test), sma_sResult.rec, sma_sResult.fpr))\n",
    "\n",
    "sma_sResult.ctab_bin # you can also try with sma_sResult.ctab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacked Classifier: Adversarial Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial Recall (baseline): 0.997\n",
      "Adversarial Recall (attack): 0.596\n"
     ]
    }
   ],
   "source": [
    "adv_sPred_base = sma_sClf.predict(mal_base[small_features])\n",
    "adv_sPred_adv = sma_sClf.predict(mal_adv[small_features])\n",
    "\n",
    "adv_ensstk_base_rec =  recall_score(mal_base['Nature'], adv_sPred_base)\n",
    "adv_ensstk_adv_rec = recall_score(mal_adv['Nature'], adv_sPred_adv)\n",
    "\n",
    "print(\"Adversarial Recall (baseline): {:.3f}\".format(adv_ensstk_base_rec))\n",
    "print(\"Adversarial Recall (attack): {:.3f}\".format(adv_ensstk_adv_rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can now inspect the results by referring to the \"Result\" variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR 0.9999654346022675 0.9939164899990782 0.9867038436722279 0.997626509355701 0.5972555074200387 0.9952069315144253 \n",
      "FPR 0.29633275410066595 0.1609731108812037 0.05773576945870207 0.27443575037415757 0.015378125094167139 0.18512008196309648 \n",
      "Training Time 0.014950037002563477 0.017932415008544922 0.04498577117919922 0.04498577117919922 0.04498577117919922 0.06286764144897461 \n",
      "Inference Time 0.09070611000061035 0.0946507453918457 0.5190906524658203 0.7697935104370117 0.7697935104370117 0.5110363960266113 \n",
      "Accuracy 0.9065516852786974 0.9111666818711128 0.9782806576870341 0.9782814084247397\n"
     ]
    }
   ],
   "source": [
    "## BASELINE RESULTS (on Complete Feature Set)\n",
    "print(\n",
    "    \"TPR\",\n",
    "    bResult.rec,\n",
    "    mResult.rec,\n",
    "    ens_avgREC,\n",
    "    enslorResult.rec,\n",
    "    ensvotResult.rec,\n",
    "    sResult.rec,\n",
    "    \"\\nFPR\",\n",
    "    bResult.fpr,\n",
    "    mResult.fpr,\n",
    "    ens_avgFPR,\n",
    "    enslorResult.fpr,\n",
    "    ensvotResult.fpr,\n",
    "    sResult.fpr,\n",
    "    \"\\nTraining Time\",\n",
    "    bResult.time,\n",
    "    mResult.time,\n",
    "    ens_time,\n",
    "    enslorResult.time,\n",
    "    ensvotResult.time,\n",
    "    sResult.time,\n",
    "    \"\\nInference Time\",\n",
    "    bResult.infer_time,\n",
    "    mResult.infer_time,\n",
    "    fakeEns_infer_time,\n",
    "    enslorResult.infer_time,\n",
    "    ensvotResult.infer_time,\n",
    "    sResult.infer_time, \n",
    "    \"\\nAccuracy\",\n",
    "    mResult.acc_multi,   # This is the accuracy on the multiclassification\n",
    "    mResult.acc,         # This is the accuracy on the binary classification\n",
    "    mcResult.acc_multic, # This is the accuracy on the multiclassification AFTER the output of the binary classifier (it does not account for benign samples, which are false positives)\n",
    "    mcResult.acc_multi   # This is the accuracy on the multiclassification on the whole test portion of the malicious dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR 0.993697575813439 0.9941469259839617 0.9895382062862936 0.9971656373859342 0.2386855931422251 0.9971656373859342 \n",
      "FPR 0.33282441214580594 0.274415661379913 0.08122761611717687 0.32686802535231074 0.024598973452394146 0.3236236527818235 \n",
      "Training Time 0.006976604461669922 0.0059888362884521484 0.0387723445892334 0.0387723445892334 0.0387723445892334 0.05571413040161133 \n",
      "Inference Time 0.041860103607177734 0.04488706588745117 0.21473908424377441 0.29760026931762695 0.29760026931762695 0.20990777015686035 \n",
      "Accuracy 0.8391942001298639 0.8506672963096126 0.9841614006609078 0.979260761360494\n"
     ]
    }
   ],
   "source": [
    "## BASELINE RESULTS (on Essential Feature Set)\n",
    "print(\n",
    "    \"TPR\",\n",
    "    sma_bResult.rec,\n",
    "    sma_mResult.rec,\n",
    "    sma_ens_avgREC,\n",
    "    sma_enslorResult.rec,\n",
    "    sma_ensvotResult.rec,\n",
    "    sma_sResult.rec,\n",
    "    \"\\nFPR\",\n",
    "    sma_bResult.fpr,\n",
    "    sma_mResult.fpr,\n",
    "    sma_ens_avgFPR,\n",
    "    sma_enslorResult.fpr,\n",
    "    sma_ensvotResult.fpr,\n",
    "    sma_sResult.fpr,\n",
    "    \"\\nTraining Time\",\n",
    "    sma_bResult.time,\n",
    "    sma_mResult.time,\n",
    "    sma_ens_time,\n",
    "    sma_enslorResult.time,\n",
    "    sma_ensvotResult.time,\n",
    "    sma_sResult.time,\n",
    "    \"\\nInference Time\",\n",
    "    sma_bResult.infer_time,\n",
    "    sma_mResult.infer_time,\n",
    "    sma_fakeEns_infer_time,\n",
    "    sma_enslorResult.infer_time,\n",
    "    sma_ensvotResult.infer_time,\n",
    "    sma_sResult.infer_time, \n",
    "    \"\\nAccuracy\",\n",
    "    sma_mResult.acc_multi,   # This is the accuracy on the multiclassification\n",
    "    sma_mResult.acc,         # This is the accuracy on the binary classification\n",
    "    sma_mcResult.acc_multic, # This is the accuracy on the multiclassification AFTER the output of the binary classifier (it does not account for benign samples, which are false positives)\n",
    "    sma_mcResult.acc_multi   # This is the accuracy on the multiclassification on the whole test portion of the malicious dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open World assessment: performance against one unknown attack (averaged for all attacks in the dataset)\n",
      "      BD: TPR=0.731778\tFPR=0.289414\n",
      "      MD (binarized) CLF: TPR=0.668178\tFPR=0.171463\n",
      "      ED-o: TPR=0.816140\tFPR=0.258750\n",
      "      ED-v: TPR=0.175645\tFPR=0.010300\n",
      "      ED-s: TPR=0.815693\tFPR=0.181915\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "## Open World: One attack against all (averaged results)\n",
    "\n",
    "print('''Open World assessment: performance against one unknown attack (averaged for all attacks in the dataset)\n",
    "      BD: TPR={:5f}\\tFPR={:5f}\n",
    "      MD (binarized) CLF: TPR={:5f}\\tFPR={:5f}\n",
    "      ED-o: TPR={:5f}\\tFPR={:5f}\n",
    "      ED-v: TPR={:5f}\\tFPR={:5f}\n",
    "      ED-s: TPR={:5f}\\tFPR={:5f}\n",
    "      '''.format(oaac_bin_rec, oaac_bin_fpr,\n",
    "                 oaac_multi_rec, oaac_multi_fpr,\n",
    "                 oaac_enslor_rec, oaac_enslor_fpr,\n",
    "                 oaac_ensvot_rec, oaac_ensvot_fpr,\n",
    "                 oaac_ensstk_rec, oaac_ensstk_fpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BD (before, after): 0.9937319245526507 0.9998847780248649 \n",
      "MD  (before, after): 0.9941812902556776 0.9035476846144097 \n",
      "ED-o  (before, after): 0.9972001060042172 0.6251368260954729 \n",
      "ED-v  (before, after): 0.23869384368986854 0.0 \n",
      "ED-s  (before, after): 0.9972001060042172 0.595801311226077\n"
     ]
    }
   ],
   "source": [
    "## Adversarial Attacks \n",
    "\n",
    "print(\n",
    "    \"BD (before, after):\",\n",
    "    adv_bin_base_rec,\n",
    "    adv_bin_adv_rec,\n",
    "    \"\\nMD  (before, after):\",\n",
    "    adv_multi_base_rec,\n",
    "    adv_multi_adv_rec,\n",
    "    \"\\nED-o  (before, after):\",\n",
    "    adv_enslor_base_rec,\n",
    "    adv_enslor_adv_rec, \n",
    "    \"\\nED-v  (before, after):\",\n",
    "    adv_ensvot_base_rec,\n",
    "    adv_ensvot_adv_rec, \n",
    "    \"\\nED-s  (before, after):\",\n",
    "    adv_ensstk_base_rec, \n",
    "    adv_ensstk_adv_rec,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
